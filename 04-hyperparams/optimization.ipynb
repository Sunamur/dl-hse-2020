{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/m12sl/dl-hse-2020/blob/master/04-hyperparams/optimization.ipynb)\n",
    "\n",
    "\n",
    "**Цели тетрадки**\n",
    "\n",
    "1. Познакомиться с процедурой подбора гиперпараметров\n",
    "3. Протренировать сверточную сеть\n",
    "\n",
    "**План**\n",
    "\n",
    "1. Написать функцию для Learning Rate Range Test и отладить ее на FashionMNIST\n",
    "2. Подобрать параметры и натренировать сверточную сеть на Imagenette\n",
    "\n",
    "\n",
    "**Настоятельно рекомендуется воспользоваться колабом**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Конспект.  \n",
    "Гиперпараметры. Хотим наилучшее качество за наименьшее время/эпохи.  \n",
    "\n",
    "### BatchSize.\n",
    "- Утилизация гпу\\врам\n",
    "- Степени двойки - массивы часто паддятся под них \"нулями\"\n",
    "- большой бс - более стабильное обучение\n",
    "- некоторые слои выигрывают от большого бс (BatchNorm)\n",
    "- маленькие бс шумнее, но могут быть точнее in the end\n",
    "- можно дергать динамически!\n",
    "- Самая простая эвристика - повышай утилизацию гпу\n",
    "### LearningRate.\n",
    "- Большой - быстрее сходимся\n",
    "- маленький - лучше результат\n",
    "- идеальный - ровно съезжаем к оптимуму\n",
    "- Расписание - лав\n",
    "- reduce on platau - славно, но не помогает взять лр для начала\n",
    "- прогрев/warmup - начать с маленького, затем большой, затем снижение по расписанию\n",
    "- если между весами и градиентом большая разница в порядках, то из-за ограниченности флоутов в памяти апдейты будут пропадать\n",
    "- вообще в целом расстояние, пройденное сеткой по плоскости лосса, равно $ steps \\times lr $. Можем от этого отталкиваться!\n",
    "- $t = \\frac{steps}{total};a - minimal \\ lr, b - maximum\\ lr;  lr = (1-t)\\times log(a)+t\\times log(b)$\n",
    "- Циклический LR.\n",
    "    \n",
    "### Графики\n",
    "- За обучением надо следить.\n",
    "- лосс на трейне.\n",
    "- лосс на валидации\n",
    "- метрики - ваще все какие есть. Бинарная -> аук  \n",
    "   \n",
    "### Регуляризация\n",
    "- регуляриация, оптимизация, архитектура, аугментации - одна сатана, одна задача по факту.\n",
    "- L2 - $\\min_{\\theta} \\sum_{i=1}^{N} l(f(x_i,\\theta), y_i) + \\frac{\\lambda}{2} \\lVert \\theta \\rVert_2^2$\n",
    "- Дропаут\n",
    "    - мешает коадаптации\n",
    "    - Обычно слои/эмбеддинги, реже свертки\n",
    "    - В инференсе лучше отключать! Домножать веса на $\\frac{1}{1-p}$  \n",
    "-Аугментации\n",
    "    - менять данные чтобы добавить данные!\n",
    "    - Для картинок - маст\n",
    "        - флип\n",
    "        - рандом кроп\\рескейл\n",
    "        - сдвиги - редко\n",
    "        - случайные модификации цвета\n",
    "        - синтез синтетических данных\n",
    "    - для звука - случайный шум фона, тональность\n",
    "    - для текстов - реже (дискретные данные)\n",
    "        - замена на синонимы по словарю\n",
    "- Плохая регуляризация\n",
    "\n",
    "\n",
    "\n",
    "- LR для каждого параметра! Когда в каньон попадаем, можем для "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install requirements\n",
    "! pip install torchviz torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.datasets import FashionMNIST\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "# имеет смысл добавить нормирование картинок\n",
    "\n",
    "train_dataset = FashionMNIST(\"./tmp\", train=True, download=True, transform=transform)\n",
    "val_dataset = FashionMNIST(\"./tmp\", train=False, download=True, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=32)\n",
    "val_loader = DataLoader(val_dataset, shuffle=False, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(0.2 балла)** Допишите тренировочный цикл и проверьте, что он работает на какой-нибудь сверточной сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "def train(model, optimizer, dataloader): \n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    logs = defaultdict(list)\n",
    "    for x, y in tqdm(dataloader):\n",
    "        <your code here>\n",
    "        \n",
    "        # у вас должно быть две скалярных переменных: с метрикой и лоссом\n",
    "        logs['acc'].append(acc.item())\n",
    "        logs['loss'].append(loss.item())\n",
    "    return logs\n",
    "\n",
    "def validate(model, dataloader):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    logs = defaultdict(list)\n",
    "    for x, y in tqdm(dataloader):\n",
    "        <your code>\n",
    "        # у вас должно быть две скалярных переменных: с метрикой и лоссом\n",
    "        logs['acc'].append(acc.item())\n",
    "        logs['loss'].append(loss.item())\n",
    "    \n",
    "    return {k: [np.mean(v)] for k, v in logs.items()}\n",
    "\n",
    "def plot_logs(logs):\n",
    "    clear_output()\n",
    "    plt.figure()\n",
    "    plt.plot(logs['acc'], zorder=1)\n",
    "    plt.scatter(logs['steps'], logs['val_acc'], marker='+', s=180, c='orange', label='val', zorder=2)\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure()\n",
    "    # для отображения подписей воспользуйтесь label&legend\n",
    "    # plt.plot(..., label=name)\n",
    "    # plt.legend() \n",
    "    <your code>        \n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def train_model(model, optimizer, train_loader, val_loader, epochs=10):\n",
    "    logs = defaultdict(list)\n",
    "    for epoch in range(epochs):\n",
    "        train_logs = train(model, opt, train_loader)\n",
    "        \n",
    "        # вы вольны переписать объединение логов\n",
    "        for k, v in train_logs.items():\n",
    "            logs[k].extend(v)\n",
    "\n",
    "        val_logs = validate(model, val_loader)\n",
    "        for k, v in val_logs.items():\n",
    "            logs[f'val_{k}'].extend(v)\n",
    "        logs['steps'].append(len(logs['loss']))\n",
    "\n",
    "        clear_output()\n",
    "        plot_logs(logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = <задайте какую-нибудь сверточную сеть>\n",
    "\n",
    "opt = torch.optim.SGD(cnn.parameters(), lr=0.01)\n",
    "train_model(cnn, opt, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LRRT (Find LR)\n",
    "\n",
    "**(0.1 балла)** Напишите функцию Learning Rate Range Test:\n",
    "    \n",
    "$$t = \\frac{\\mathrm{step}}{\\mathrm{total}}\\\\\n",
    "\\mathrm {lr} = \\exp((1-t)\\log a + t \\log b) \n",
    "$$\n",
    "\n",
    "Чтобы поменять LR можно обойти оптимизируемые параметры следующим способом:\n",
    "```python\n",
    "for param_group in optimizer.param_groups:\n",
    "    param_group['lr'] = lr\n",
    "```\n",
    "\n",
    "**(0.2 балла)** Постройте графики Loss/Acc vs lr.\n",
    "\n",
    "Напишите словами, LR из какого диапазона вы выберете для тренировки сети.\n",
    "И протренируйте вашу сеть с новыми гиперпараметрами.\n",
    "\n",
    "**NB: вы можете попробовать поменять оптимизатор и параметры в оптимизаторе**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_lr(model, optimizer, dataloader, min_lr, max_lr):\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    \n",
    "    logs = defaultdict(list)\n",
    "    for x, y in tqdm(dataloader):\n",
    "        <your code>\n",
    "        \n",
    "        logs['loss'].append(acc.item())\n",
    "        logs['acc'].append(loss.item())\n",
    "        logs['lr'].append(lr)\n",
    "        \n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(logs['lr'], logs['loss'])\n",
    "    plt.set_xscale('log')\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "\n",
    "find_lr(model, optimizer, train_loader, 1e-6, 10.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imagenette\n",
    "\n",
    "Скачаем датасет и напишем загрузчики данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! wget https://s3.amazonaws.com/fast-ai-imageclas/imagenette2-160.tgz\n",
    "! tar xf imagenette2-160.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(160),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.CenterCrop(160),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "train_dataset = ImageFolder(\"./imagenette2-160/train/\", transform=train_transform)\n",
    "val_dataset = ImageFolder(\"./imagenette2-160/val/\", transform=val_transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(0.1 балла)** Преобразуйте выходной слой для классификации на 10 классов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "\n",
    "model = models.resnet18(pretrained=False)\n",
    "# преобразуйте выходной слой\n",
    "<your code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(0.2 балла)** Выберете оптимизатор и определите интересный для тренировки интервал LR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "find_lr(model, opt, train_loader, 1e-6, 10.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(0.2 балла)** Натренируйте модель с выбранными гиперпараметрами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ...\n",
    "opt = torch.optim.SGD(model.parameters(), lr=...)\n",
    "train_model(model, opt, train_loader, val_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CNNs",
   "language": "python",
   "name": "cnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
